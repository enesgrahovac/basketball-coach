{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basketball Shot Analysis - Data Synchronization\n",
        "\n",
        "This notebook synchronizes evaluation data from Supabase, downloads missing videos, and prepares the ground truth dataset for model evaluation.\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. Ensure you have your Supabase credentials configured\n",
        "2. Install required packages: `pip install -r ../requirements.txt`\n",
        "3. Run cells in order to sync your evaluation dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.append(str(Path('../src').resolve()))\n",
        "\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from data_manager import EvaluationDataManager\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('../../.env')  # Adjust path as needed\n",
        "\n",
        "# Supabase configuration\n",
        "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
        "SUPABASE_SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')  # Use service role for full access\n",
        "SUPABASE_BUCKET = os.getenv('SUPABASE_STORAGE_BUCKET', 'clips')\n",
        "\n",
        "if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:\n",
        "    print(\"âš ï¸  Missing Supabase credentials!\")\n",
        "    print(\"Please ensure SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY are set in your .env file\")\n",
        "else:\n",
        "    print(\"âœ… Supabase credentials loaded\")\n",
        "    print(f\"URL: {SUPABASE_URL}\")\n",
        "    print(f\"Bucket: {SUPABASE_BUCKET}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data manager\n",
        "data_manager = EvaluationDataManager(\n",
        "    supabase_url=SUPABASE_URL,\n",
        "    supabase_key=SUPABASE_SERVICE_ROLE_KEY,\n",
        "    data_dir='../data'\n",
        ")\n",
        "\n",
        "print(\"âœ… Data manager initialized\")\n",
        "print(f\"ğŸ“ Data directory: {data_manager.data_dir}\")\n",
        "print(f\"ğŸ¥ Videos directory: {data_manager.videos_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch evaluation dataset from Supabase\n",
        "print(\"ğŸ”„ Fetching evaluation dataset from Supabase...\")\n",
        "df = data_manager.fetch_evaluation_dataset()\n",
        "\n",
        "print(f\"\\nğŸ“Š Dataset Overview:\")\n",
        "print(f\"Total clips: {len(df)}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Display first few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze ground truth distribution\n",
        "print(\"ğŸ“ˆ Ground Truth Analysis:\")\n",
        "print(\"\\nShot Type Distribution:\")\n",
        "print(df['ground_truth_shot_type'].value_counts())\n",
        "\n",
        "print(\"\\nResult Distribution:\")\n",
        "print(df['ground_truth_result'].value_counts())\n",
        "\n",
        "print(\"\\nUser Corrections Analysis:\")\n",
        "shot_type_corrections = (df['ground_truth_shot_type'] != df['original_shot_type']).sum()\n",
        "result_corrections = (df['ground_truth_result'] != df['original_result']).sum()\n",
        "\n",
        "print(f\"Shot type corrections: {shot_type_corrections}/{len(df)} ({shot_type_corrections/len(df)*100:.1f}%)\")\n",
        "print(f\"Result corrections: {result_corrections}/{len(df)} ({result_corrections/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Show examples of corrections\n",
        "corrections_df = df[\n",
        "    (df['ground_truth_shot_type'] != df['original_shot_type']) | \n",
        "    (df['ground_truth_result'] != df['original_result'])\n",
        "]\n",
        "\n",
        "if len(corrections_df) > 0:\n",
        "    print(f\"\\nğŸ” Sample Corrections:\")\n",
        "    for _, row in corrections_df.head(3).iterrows():\n",
        "        print(f\"Clip {row['clip_id'][:8]}:\")\n",
        "        if row['ground_truth_shot_type'] != row['original_shot_type']:\n",
        "            print(f\"  Shot type: {row['original_shot_type']} â†’ {row['ground_truth_shot_type']}\")\n",
        "        if row['ground_truth_result'] != row['original_result']:\n",
        "            print(f\"  Result: {row['original_result']} â†’ {row['ground_truth_result']}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download missing videos\n",
        "print(\"â¬‡ï¸  Downloading missing videos...\")\n",
        "downloaded_clips = data_manager.download_missing_videos(df, SUPABASE_BUCKET)\n",
        "\n",
        "if downloaded_clips:\n",
        "    print(f\"âœ… Downloaded {len(downloaded_clips)} new videos\")\n",
        "else:\n",
        "    print(\"âœ… All videos already present locally\")\n",
        "\n",
        "# Check video availability\n",
        "video_paths = [data_manager.videos_dir / f\"{clip_id}.mp4\" for clip_id in df['clip_id']]\n",
        "videos_available = sum(1 for path in video_paths if path.exists())\n",
        "\n",
        "print(f\"\\nğŸ“¹ Video Status:\")\n",
        "print(f\"Available locally: {videos_available}/{len(df)} ({videos_available/len(df)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ground truth dataset\n",
        "print(\"ğŸ’¾ Saving ground truth dataset...\")\n",
        "data_manager.save_ground_truth(df)\n",
        "\n",
        "# Get dataset statistics\n",
        "stats = data_manager.get_dataset_stats()\n",
        "print(\"\\nğŸ“Š Final Dataset Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"{key}:\")\n",
        "        for sub_key, sub_value in value.items():\n",
        "            print(f\"  {sub_key}: {sub_value}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "print(f\"\\nâœ… Data synchronization complete!\")\n",
        "print(f\"ğŸ“ Ground truth saved to: {data_manager.ground_truth_file}\")\n",
        "print(f\"ğŸ¥ Videos stored in: {data_manager.videos_dir}\")\n",
        "print(f\"\\nğŸš€ Ready for model evaluation!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
